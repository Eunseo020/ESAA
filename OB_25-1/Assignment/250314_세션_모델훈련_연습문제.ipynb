{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n",
        "\n",
        "확률적 경사하강법, 배치경사하강법, 미니배치경사하강법\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___\n",
        "\n",
        "학습률 줄이기, 모델을 복잡하게 만들기\n",
        "- 수렴이 아닌 발산 중인 것 -> 학습율이 커서 오차가 커지는 것\n",
        "- 과소적합 (모델이 단순해서 오차가 클 수 있다)"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___\n",
        "\n",
        "과소적합 문제이므로 높은 편향이 문제이다. α를 줄여야한다.\n"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "  - : 규제가 있는 모델이 일반적으로 더 성능이 좋기 때문이다.\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "  - : 중요하지 않은 것의 가중치를 0으로 만들어서 중요한 것만 추출하여 사용가능하다.\n",
        "- 라쏘 회귀 대신 엘라스틱넷\n",
        "  - : 사용하는 특성이 적으면 라쏘 대신 엘라스틱넷 회귀를 이용할 수 있다"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **추가) 조기 종료를 사용한 배치 경사 하강법으로 iris 데이터를 활용해 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "iris.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11_xzmSPD6KU",
        "outputId": "1cd06f09-cc38-45e2-e281-386944091db6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 넓이\n",
        "y = iris[\"target\"]"
      ],
      "metadata": {
        "id": "7WQM3ggKJSAk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "intercept = np.ones([len(X), 1])\n",
        "XX = np.concatenate((intercept, X), axis=1)\n",
        "print(XX.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3aH_5u2JYpW",
        "outputId": "afa4ec50-1d84-4617-c961-f88937c41bea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 샘플에 편향 추가\n",
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]"
      ],
      "metadata": {
        "id": "tjVVdHQvXjw8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 수동으로 train_test_split()하기"
      ],
      "metadata": {
        "id": "1oplC8_hX4Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "metadata": {
        "id": "ClYjHwmPXpiR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원핫 벡터로 바꾸는 함수. 타깃 클래스의 확률은 1이고 나머지는 0임.\n",
        "def to_one_hot(y):\n",
        "    n_classes = y.max() + 1\n",
        "    m = len(y)\n",
        "    Y_one_hot = np.zeros((m, n_classes))\n",
        "    Y_one_hot[np.arange(m), y] = 1\n",
        "    return Y_one_hot"
      ],
      "metadata": {
        "id": "i8WY6QEsXrzH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzT1UHdQX3WH",
        "outputId": "b0f485a2-188e-4e8a-b591-484e9b0a355e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_one_hot(y_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el-PmsVVYAUb",
        "outputId": "d75667f8-3801-4ec7-e58c-8a35fda4c670"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)"
      ],
      "metadata": {
        "id": "dB4Pc9UgYBhw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소프트 맥스 함수 만들기\n",
        "def softmax(logits):\n",
        "    exps = np.exp(logits)\n",
        "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
        "    return exps / exp_sums"
      ],
      "metadata": {
        "id": "WtFwMEqGYECP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_inputs = X_train.shape[1] # == 3 (특성 2개와 편향)\n",
        "n_outputs = len(np.unique(y_train))   # == 3 (3개의 붓꽃 클래스)"
      ],
      "metadata": {
        "id": "yTQbrzN0YH5P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 비용함수 공식을 구현해 학습\n",
        "eta = 0.01\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "    Theta = Theta - eta * gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw7vyKOUYJ2v",
        "outputId": "19171b21-adc1-420a-9820-fbeb98e40483"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.3588286023324982\n",
            "500 0.760783557929906\n",
            "1000 0.6363200820308196\n",
            "1500 0.5628849316412955\n",
            "2000 0.5141596027346715\n",
            "2500 0.4788614976596295\n",
            "3000 0.45163105967551326\n",
            "3500 0.4296512224414479\n",
            "4000 0.4113094819712394\n",
            "4500 0.395616233236116\n",
            "5000 0.38192859231089266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyBCm9oFYQ61",
        "outputId": "bc3e39df-973c-4036-bbf1-b3ea11ef4bbf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.27968049, -0.84249833, -2.84758359],\n",
              "       [-1.77134616, -0.43839553, -0.77843297],\n",
              "       [-1.54744158, -0.83726734,  1.46456725]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGAj6b9XYUMb",
        "outputId": "1bdacc4f-a73a-4390-bb45-4e02d30ff010"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 규제를 추가하여 다시 학습시키기\n",
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1  # 규제 하이퍼파라미터\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "        loss = xentropy_loss + alpha * l2_loss\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfzUBFcrYV4u",
        "outputId": "14365701-8d12-41a8-d226-39e279b3ac4f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 3.3947166728838187\n",
            "500 0.5281962685662476\n",
            "1000 0.5012587868662423\n",
            "1500 0.49352333492981404\n",
            "2000 0.4907206090537449\n",
            "2500 0.48961292857485217\n",
            "3000 0.4891554474140104\n",
            "3500 0.4889616972875721\n",
            "4000 0.4888783835861583\n",
            "4500 0.4888422151211472\n",
            "5000 0.4888264174737881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-0s2b6CY5qU",
        "outputId": "98a5f3cc-0567-4d8b-f3c4-db5c921b9b46"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료 추가\n",
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1  # 규제 하이퍼파라미터\n",
        "best_loss = np.infty\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    xentropy_loss = -np.mean(np.sum(Y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:\n",
        "        print(iteration - 1, best_loss)\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5UruYIjY8S1",
        "outputId": "1f0c6adc-d8a6-49fb-d3dd-c9a5e1acc289"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 4.291869122740602\n",
            "500 0.5435642446601654\n",
            "1000 0.5241657707699207\n",
            "1500 0.5176387378645624\n",
            "2000 0.5149946165182178\n",
            "2500 0.5138247471554056\n",
            "3000 0.5132717483990569\n",
            "3500 0.5129946584897491\n",
            "4000 0.5128481293812162\n",
            "4500 0.5127667264198179\n",
            "5000 0.5127195044556722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLwJPYneY-y-",
        "outputId": "44f5cd98-8146-4c5c-ff95-5f9d0594683b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 세트에 대한 최종 정확도\n",
        "\n",
        "logits = X_test.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ6d8wwFZAxp",
        "outputId": "7fa10578-5021-4ec9-d252-167e7b5d1a44"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}